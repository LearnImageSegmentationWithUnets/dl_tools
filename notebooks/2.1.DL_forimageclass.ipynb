{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Deep Learning for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/real_deep_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Deep Learning?\n",
    "\n",
    "* A form of machine learning\n",
    "\n",
    "![](https://i.ytimg.com/vi/k4ovpelG9vs/maxresdefault.jpg)\n",
    "\n",
    "* The application of Artificial Neural Networks with more than one hidden layer\n",
    "\n",
    "![](https://i1.wp.com/www.michaelchimenti.com/wp-content/uploads/2017/11/Deep-Neural-Network-What-is-Deep-Learning-Edureka.png)\n",
    "\n",
    "* The input of each layer is the output of the previous one\n",
    "\n",
    "* The layer does not need to learn the whole concept at once, but actually build a chain of features that build that knowledge.\n",
    "\n",
    "* It learns the best way to map inputs to outputs (you don’t need to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Picture23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Picture24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinction between Machine and Deep Learning\n",
    "\n",
    "Machine learning ...\n",
    "* requires extracting features from data to input to the model\n",
    "* requires fine-tuning of model architecture\n",
    "* requires fine-tuning of model hyperparameters\n",
    "* performance tends to plateau with more data\n",
    "* lots of different models\n",
    "\n",
    "Deep learning ...\n",
    "* automatically extract features from data\n",
    "* automatically fine-tunes hyperparameters\n",
    "* performance doesn't tend to plateau with more data\n",
    "* requires fine-tuning of model architecture\n",
    "* just one model - the artificial neural network\n",
    "\n",
    "![](https://images.xenonstack.com/blog/machine-learning-vs-deep-learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use DL for image classification?\n",
    "\n",
    "* No ‘feature engineering’\n",
    "* Instead, hierarchy of features automatically learned from data\n",
    "* Potentially more powerful -  learns more abstract information\n",
    "* Performance doesn’t plateau with added data\n",
    "\n",
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/Why-Deep-Learning-1024x742.png)\n",
    "\n",
    "![](figs/Picture10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Why now?\n",
    "\n",
    "### 1. Accessing remotely sensed data is easier than ever before\n",
    "\n",
    "![](figs/Picture3.jpg)\n",
    "\n",
    "### 2. Better hardware, better software\n",
    "\n",
    "![](figs/Picture4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## DL basic workflow\n",
    "\n",
    "DL workflows are scalable and should keep getting better with more and more data. But how much is enough? What is too much?\n",
    "\n",
    "![](figs/Picture1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Problems DL is supposed to overcome\n",
    "\n",
    "![](figs/Picture2.png)\n",
    "\n",
    "\n",
    "### Intra-class variation\n",
    "\n",
    "This is water from 5 different data sets\n",
    "\n",
    "![](figs/Picture5.png)\n",
    "\n",
    "\n",
    "... woody vegetation ...\n",
    "\n",
    "![](figs/Picture6.png)\n",
    "\n",
    "\n",
    "... sand ...\n",
    "\n",
    "![](figs/Picture7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. \n",
    "\n",
    "CNN architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. \n",
    "\n",
    "![](http://cs231n.github.io/assets/cnn/convnet.jpeg)\n",
    "\n",
    "\n",
    "The layers consist of hierarchical filters that are designed to extract features of increasingly complexity\n",
    "\n",
    "![](figs/Picture8.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide33.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide35.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide36.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide37.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature extraction\n",
    "\n",
    "![](figs/Picture19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Picture20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Limitations\n",
    "\n",
    "1. Very data hungry\n",
    "2. Computationally intensive to train and deploy\n",
    "3. Finicky to optimize (choice of architecture, parameters)\n",
    "4. Often require expert knowledge to design and fine tune architectures\n",
    "\n",
    "### (Partial) Solution = Transfer Learning\n",
    "\n",
    "![](figs/Picture9.png)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*yTJ6h-kJVJ1goDEvNd07xg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Drawbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It can be very difficult to interpret a model produced with deep learning. Such models may have many layers and thousands of nodes; interpreting each of these individually is impossible.\n",
    "    * We therefore evaluate deep learning models by measuring how well they predict, treating the architecture itself as a “black box.”\n",
    "    \n",
    "* Deep learning also shares other machine learning methods’ propensity to overlearn the training data\n",
    "\n",
    "* DL models require a great deal of computing power to build. For simpler problems with small data sets, deep learning may not produce sufficient added benefit over simpler methods to justify the cost and time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning for the Natural Sciences\n",
    "\n",
    "* Many claims about the efficacy of DCNNs for image classification are largely based upon analyses of conventional photographic imagery of familiar, mostly anthropogenic objects\n",
    "\n",
    "* Much more work required for the image classification of natural textures and objects. \n",
    " \n",
    "* Images of natural landscapes / objects / landuse/cover ...\n",
    "    * tend to be large scale\n",
    "    * tend to be taken from the air or at high vantage, with a nadir (vertical) or oblique perspective. \n",
    "    * Variations in lighting and weather greatly affect distributions of color, contrast, and brightness\n",
    "    * The distinction of certain objects and features may be difficult against similar backgrounds, for example, groundcover between vegetation canopies.\n",
    "    \n",
    "\n",
    "* We need to build our own shared databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Picture21.png)\n",
    "\n",
    "![](figs/Picture22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
