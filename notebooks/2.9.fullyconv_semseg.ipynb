{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully convolutional semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we retrain the VGG16 model to carry out 'fully convolutional' semantic segmentation\n",
    "\n",
    "We will implement the approach of [Long et al. 2015](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide47.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/Slide48.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the Grand Canyon sandbars data set. First we'll copy over the files from S3 to our local drive, then we'll train the model, and test the model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/dl_tools_fullyconv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the S3 file structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in our s3fs library and explore the contents of the 'fully_conv_semseg' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "root = 'esipfed/cdi-workshop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls(root+'/fully_conv_semseg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls(root+'/fully_conv_semseg/data_gc/labels/gtFine/train/gc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see a very specific folder structure for each of the datasets\n",
    "\n",
    "* top_level (data_gc)\n",
    "    * samples\n",
    "        * RGB\n",
    "            * train or val\n",
    "                * site name (gc)\n",
    "            \n",
    "* top_level (data_gc)\n",
    "    * labels\n",
    "        * gtFine\n",
    "            * train (or val)\n",
    "                * site name (gc)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = root+'/fully_conv_semseg/data_gc/samples/RGB/train/gc'\n",
    "files = [f for f in fs.ls(direc) if f.endswith('.png')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data structure for samples (images to train with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('data') ##root+os.sep+\n",
    "os.mkdir('data'+os.sep+'samples')  \n",
    "os.mkdir('data'+os.sep+'samples'+os.sep+'RGB')\n",
    "os.mkdir('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'train')\n",
    "os.mkdir('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'val')\n",
    "os.mkdir('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'train'+os.sep+'data')\n",
    "os.mkdir('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'val'+os.sep+'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to copy over the files we need (this takes a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread, imwrite\n",
    "for file in files:\n",
    "    print(\"working on \",file)\n",
    "    with fs.open(file, 'rb') as fim:\n",
    "        image = imread(fim)   \n",
    "        imwrite('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'train'+os.sep+'data'+os.sep+file.split('/')[-1], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next bit finds the 'validation' files and copies them over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = root+'/fully_conv_semseg/data_gc/samples/RGB/val/gc'\n",
    "files = [f for f in fs.ls(direc) if f.endswith('.png')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(\"working on \",file)\n",
    "    with fs.open(file, 'rb') as fim:\n",
    "        image = imread(fim)   \n",
    "        imwrite('data'+os.sep+'samples'+os.sep+'RGB'+os.sep+'val'+os.sep+'data'+os.sep+file.split('/')[-1], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recreate the file structure for the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data'+os.sep+'labels')\n",
    "os.mkdir('data'+os.sep+'labels'+os.sep+'gtFine')\n",
    "os.mkdir('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'train')\n",
    "os.mkdir('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'val')\n",
    "os.mkdir('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'train'+os.sep+'data')\n",
    "os.mkdir('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'val'+os.sep+'data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = root+'/fully_conv_semseg/data_gc/labels/gtFine/train/gc'\n",
    "files = [f for f in fs.ls(direc) if f.endswith('.png')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    print(\"working on \",file)\n",
    "    with fs.open(file, 'rb') as fim:\n",
    "        image = imread(fim)   \n",
    "        imwrite('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'train'+os.sep+'data'+os.sep+file.split('/')[-1], image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = root+'/fully_conv_semseg/data_gc/labels/gtFine/val/gc'\n",
    "files = [f for f in fs.ls(direc) if f.endswith('.png')]\n",
    "\n",
    "for file in files:\n",
    "    print(\"working on \",file)\n",
    "    with fs.open(file, 'rb') as fim:\n",
    "        image = imread(fim)   \n",
    "        imwrite('data'+os.sep+'labels'+os.sep+'gtFine'+os.sep+'val'+os.sep+'data'+os.sep+file.split('/')[-1], image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a labeldefs.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the program what the classes are and what RGB color they correspond to in the label imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's change directory and run the code in the 'semseg_fullyconv' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('semseg_fullyconv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify labels and associated red, green, and blue colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['rock','water','veg','sand','other']\n",
    "r = [102, 0, 0, 255, 255]\n",
    "g = [51, 0, 255, 255, 0]\n",
    "b = [0, 255, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labeldefs.txt', 'a') as f:\n",
    "    for item in range(len(labels)):\n",
    "        f.write(labels[item]+','+str(r[item])+','+str(g[item])+','+str(b[item])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat labeldefs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustrative purposes, to save time we are going to train the model using just 15 epochs. For real applications, you would want to train for tens to hundreds of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_direc = 'data_test10'\n",
    "data_source = 'data'\n",
    "data_dir = '../data'\n",
    "num_epochs=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model trains, we'll watch a video that explains what the VGG model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "from datetime import timedelta\n",
    "\n",
    "start=int(timedelta(hours=0, minutes=14, seconds=40).total_seconds())\n",
    "\n",
    "YouTubeVideo(\"DAOcjicFr1Y\", start=start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model by calling 'train.py'\n",
    "\n",
    "It is actually set up to download the correct model (VGG 16) from the internet before retraining it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.py --name $out_direc --data-source $data_source \\\n",
    "                                 --data-dir $data_dir --epochs $num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the VGG graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm vgg.zip\n",
    "!rm -rf vgg_graph/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we specify an output directory, and point the program to the location of the 'test' images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps_dir = '../data/samples/RGB/val/data'\n",
    "output = 'test_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./infer.py --name $out_direc --samples-dir $samps_dir \\\n",
    "                                 --output-dir $output --data-source $data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look in the output folder. The labeling looks 'blobby' because\n",
    "* we didn't train the model for very long\n",
    "* there is no post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with CRF post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll run the inference with CRF post processing to try to get more refined label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./infer_crf.py --name $out_direc --samples-dir $samps_dir \\\n",
    "                                 --output-dir $output --data-source $data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look in the output folder again - you'll see a new set of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove the model, tensorboard info, and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data_test10\n",
    "!rm -rf tb\n",
    "!rm -rf test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the labeldefs.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm labeldefs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the 'data' directory that we copied over from S3 earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equivalent function in DL-tools is called and is the same as used here. The key is getting the data in a strict format such as we did here. Then the functions are executed in the following sequence\n",
    "\n",
    "1. ```python semseg_fullyconv\\make_labels.py```\n",
    "   * this function creates label rgb images from class data in the .mat files\n",
    "2. ```python semseg_fullyconv\\train.py```\n",
    "    * this function trains the network\n",
    "3. ```python semseg_fullyconv\\infer.py``` or ```python semseg_fullyconv\\infer_crf.py```\n",
    "    * this function carries out the semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
